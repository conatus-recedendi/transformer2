{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237428f8",
   "metadata": {},
   "source": [
    "# Transformer 번역 모델 데모\n",
    "\n",
    "이 노트북은 PyTorch로 구현한 Transformer 모델의 영어-한국어 번역 데모입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a06f7",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 및 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34554fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 프로젝트 모듈\n",
    "from src.model import Transformer\n",
    "from src.data_utils import create_tokenizer, create_data_loader, prepare_sample_data, save_tokenizer\n",
    "\n",
    "# 설정\n",
    "plt.style.use('seaborn-v0_8')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337986a7",
   "metadata": {},
   "source": [
    "## 2. 샘플 데이터 준비 및 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 데이터 로드\n",
    "src_texts, tgt_texts = prepare_sample_data()\n",
    "\n",
    "print(\"샘플 번역 데이터:\")\n",
    "print(\"=\" * 60)\n",
    "for i, (src, tgt) in enumerate(zip(src_texts, tgt_texts)):\n",
    "    print(f\"{i+1:2d}. EN: {src}\")\n",
    "    print(f\"    KO: {tgt}\")\n",
    "    print()\n",
    "\n",
    "print(f\"총 데이터 개수: {len(src_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239dc95c",
   "metadata": {},
   "source": [
    "## 3. 토크나이저 생성 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee566362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 생성\n",
    "print(\"토크나이저 생성 중...\")\n",
    "src_tokenizer = create_tokenizer(src_texts * 10, vocab_size=2000)  # 데이터 확장\n",
    "tgt_tokenizer = create_tokenizer(tgt_texts * 10, vocab_size=2000)\n",
    "\n",
    "print(f\"영어 어휘 크기: {src_tokenizer.get_vocab_size()}\")\n",
    "print(f\"한국어 어휘 크기: {tgt_tokenizer.get_vocab_size()}\")\n",
    "\n",
    "# 토크나이징 예시\n",
    "example_text = \"Hello, how are you?\"\n",
    "encoded = src_tokenizer.encode(example_text)\n",
    "\n",
    "print(f\"\\n예시 텍스트: {example_text}\")\n",
    "print(f\"토큰 ID: {encoded.ids}\")\n",
    "print(f\"토큰: {encoded.tokens}\")\n",
    "print(f\"디코딩: {src_tokenizer.decode(encoded.ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c7893e",
   "metadata": {},
   "source": [
    "## 4. 모델 아키텍처 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21758f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "model = Transformer(\n",
    "    src_vocab_size=src_tokenizer.get_vocab_size(),\n",
    "    tgt_vocab_size=tgt_tokenizer.get_vocab_size(),\n",
    "    d_model=256,\n",
    "    n_heads=8,\n",
    "    n_layers=4,\n",
    "    d_ff=1024,\n",
    "    max_seq_length=128\n",
    ").to(device)\n",
    "\n",
    "# 모델 정보 출력\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"모델 정보:\")\n",
    "print(f\"총 파라미터 수: {total_params:,}\")\n",
    "print(f\"학습 가능한 파라미터 수: {trainable_params:,}\")\n",
    "print(f\"모델 크기 (MB): {total_params * 4 / (1024**2):.2f}\")\n",
    "\n",
    "# 모델 구조 출력\n",
    "print(\"\\n모델 구조:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3397ff21",
   "metadata": {},
   "source": [
    "## 5. 데이터 로더 생성 및 배치 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 생성\n",
    "train_loader = create_data_loader(\n",
    "    src_texts * 5, tgt_texts * 5,  # 데이터 확장\n",
    "    src_tokenizer, tgt_tokenizer,\n",
    "    batch_size=4, max_length=64\n",
    ")\n",
    "\n",
    "# 첫 번째 배치 분석\n",
    "for batch in train_loader:\n",
    "    print(\"배치 정보:\")\n",
    "    print(f\"Source shape: {batch['src'].shape}\")\n",
    "    print(f\"Target input shape: {batch['tgt_input'].shape}\")\n",
    "    print(f\"Target output shape: {batch['tgt_output'].shape}\")\n",
    "    \n",
    "    # 첫 번째 샘플 디코딩\n",
    "    src_decoded = src_tokenizer.decode(batch['src'][0].numpy())\n",
    "    tgt_decoded = tgt_tokenizer.decode(batch['tgt_input'][0].numpy())\n",
    "    \n",
    "    print(f\"\\n첫 번째 샘플:\")\n",
    "    print(f\"Source: {src_decoded}\")\n",
    "    print(f\"Target: {tgt_decoded}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a0dfc",
   "metadata": {},
   "source": [
    "## 6. 모델 순전파 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78413175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 순전파 테스트\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        src = batch['src'].to(device)\n",
    "        tgt_input = batch['tgt_input'].to(device)\n",
    "        \n",
    "        output = model(src, tgt_input)\n",
    "        \n",
    "        print(\"순전파 테스트 결과:\")\n",
    "        print(f\"입력 크기: {src.shape}\")\n",
    "        print(f\"출력 크기: {output.shape}\")\n",
    "        print(f\"예상 출력 크기: (batch_size={src.shape[0]}, seq_len={tgt_input.shape[1]}, vocab_size={tgt_tokenizer.get_vocab_size()})\")\n",
    "        \n",
    "        # 확률 분포 확인\n",
    "        probs = torch.softmax(output[0, -1, :], dim=-1)\n",
    "        top5_probs, top5_indices = torch.topk(probs, 5)\n",
    "        \n",
    "        print(\"\\n마지막 위치 상위 5개 토큰 확률:\")\n",
    "        for i, (prob, idx) in enumerate(zip(top5_probs, top5_indices)):\n",
    "            token = tgt_tokenizer.decode([idx.item()])\n",
    "            print(f\"{i+1}. {token}: {prob.item():.4f}\")\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05919c94",
   "metadata": {},
   "source": [
    "## 7. 학습 프로세스 시뮬레이션 (짧은 학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c508b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 짧은 학습 세션\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # 패딩 토큰 무시\n",
    "\n",
    "losses = []\n",
    "num_epochs = 5\n",
    "\n",
    "print(\"짧은 학습 시작...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        src = batch['src'].to(device)\n",
    "        tgt_input = batch['tgt_input'].to(device)\n",
    "        tgt_output = batch['tgt_output'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, tgt_input)\n",
    "        loss = criterion(output.view(-1, output.size(-1)), tgt_output.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"짧은 학습 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bc952",
   "metadata": {},
   "source": [
    "## 8. 학습 곡선 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ad317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 곡선 그리기\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(losses)+1), losses, 'b-', marker='o', linewidth=2, markersize=6)\n",
    "plt.title('Training Loss Curve', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(1, len(losses)+1))\n",
    "\n",
    "# 손실 값 표시\n",
    "for i, loss in enumerate(losses):\n",
    "    plt.annotate(f'{loss:.3f}', (i+1, loss), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"최종 손실: {losses[-1]:.4f}\")\n",
    "print(f\"손실 감소: {losses[0] - losses[-1]:.4f} ({((losses[0] - losses[-1])/losses[0]*100):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c46ef1",
   "metadata": {},
   "source": [
    "## 9. 간단한 번역 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a0ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_translate(model, text, src_tokenizer, tgt_tokenizer, max_length=64):\n",
    "    \"\"\"간단한 greedy 디코딩 번역\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 입력 텍스트 인코딩\n",
    "        src_encoding = src_tokenizer.encode(text)\n",
    "        src_ids = src_encoding.ids[:max_length-1] + [src_tokenizer.token_to_id(\"[EOS]\")]\n",
    "        src_ids += [src_tokenizer.token_to_id(\"[PAD]\")] * (max_length - len(src_ids))\n",
    "        src = torch.tensor(src_ids[:max_length], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        \n",
    "        # 디코더 시작 토큰\n",
    "        tgt = torch.tensor([[tgt_tokenizer.token_to_id(\"[BOS]\")]], dtype=torch.long).to(device)\n",
    "        \n",
    "        # 순차적 디코딩\n",
    "        for _ in range(max_length - 1):\n",
    "            output = model(src, tgt)\n",
    "            next_token = torch.argmax(output[0, -1, :], dim=-1)\n",
    "            tgt = torch.cat([tgt, next_token.unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "            \n",
    "            if next_token.item() == tgt_tokenizer.token_to_id(\"[EOS]\"):\n",
    "                break\n",
    "        \n",
    "        # 결과 디코딩\n",
    "        result_ids = tgt[0].cpu().numpy()[1:]  # BOS 토큰 제거\n",
    "        result_ids = [id for id in result_ids if id not in [0, tgt_tokenizer.token_to_id(\"[EOS]\")]]  # 패딩과 EOS 제거\n",
    "        \n",
    "        if result_ids:\n",
    "            return tgt_tokenizer.decode(result_ids)\n",
    "        return \"[번역 실패]\"\n",
    "\n",
    "# 번역 테스트\n",
    "test_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I love machine learning.\",\n",
    "    \"The weather is nice today.\",\n",
    "    \"Thank you very much.\"\n",
    "]\n",
    "\n",
    "print(\"번역 테스트 결과:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translation = simple_translate(model, sentence, src_tokenizer, tgt_tokenizer)\n",
    "    print(f\"EN: {sentence}\")\n",
    "    print(f\"KO: {translation}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb5c252",
   "metadata": {},
   "source": [
    "## 10. 어텐션 가중치 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05acffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_weights(model, src, tgt):\n",
    "    \"\"\"어텐션 가중치 추출 (간단한 버전)\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 첫 번째 인코더 레이어의 어텐션 가중치만 추출\n",
    "        src_embedded = model.src_embedding(src) * (model.d_model ** 0.5)\n",
    "        src_embedded = model.positional_encoding(src_embedded.transpose(0, 1)).transpose(0, 1)\n",
    "        \n",
    "        # 첫 번째 인코더 레이어의 self-attention\n",
    "        encoder_layer = model.encoder_layers[0]\n",
    "        \n",
    "        # Multi-head attention에서 query, key, value 계산\n",
    "        batch_size = src.size(0)\n",
    "        Q = encoder_layer.self_attention.W_q(src_embedded).view(batch_size, -1, 8, 32).transpose(1, 2)\n",
    "        K = encoder_layer.self_attention.W_k(src_embedded).view(batch_size, -1, 8, 32).transpose(1, 2)\n",
    "        \n",
    "        # 어텐션 스코어 계산\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (32 ** 0.5)\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        \n",
    "        return attention_weights\n",
    "\n",
    "# 샘플 문장으로 어텐션 시각화\n",
    "sample_text = \"Hello, how are you?\"\n",
    "src_encoding = src_tokenizer.encode(sample_text)\n",
    "src_ids = src_encoding.ids[:10] + [0] * (20 - len(src_encoding.ids[:10]))\n",
    "src = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "tgt = torch.tensor([[tgt_tokenizer.token_to_id(\"[BOS]\")]], dtype=torch.long).to(device)\n",
    "\n",
    "try:\n",
    "    attention_weights = get_attention_weights(model, src, tgt)\n",
    "    \n",
    "    # 첫 번째 헤드의 어텐션 가중치 시각화\n",
    "    attn_matrix = attention_weights[0, 0, :len(src_encoding.ids), :len(src_encoding.ids)].cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(attn_matrix, \n",
    "                xticklabels=src_encoding.tokens[:len(src_encoding.ids)],\n",
    "                yticklabels=src_encoding.tokens[:len(src_encoding.ids)],\n",
    "                annot=True, fmt='.3f', cmap='Blues')\n",
    "    plt.title('Self-Attention Weights (First Head)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Key Tokens', fontsize=12)\n",
    "    plt.ylabel('Query Tokens', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"어텐션 시각화 중 오류 발생: {e}\")\n",
    "    print(\"모델이 충분히 학습되지 않았거나 구조상 문제가 있을 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73573b",
   "metadata": {},
   "source": [
    "## 11. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디렉토리 생성\n",
    "os.makedirs('demo_checkpoints', exist_ok=True)\n",
    "os.makedirs('demo_tokenizers', exist_ok=True)\n",
    "\n",
    "# 모델 저장\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'src_vocab_size': src_tokenizer.get_vocab_size(),\n",
    "    'tgt_vocab_size': tgt_tokenizer.get_vocab_size(),\n",
    "    'losses': losses\n",
    "}, 'demo_checkpoints/demo_model.pth')\n",
    "\n",
    "# 토크나이저 저장\n",
    "save_tokenizer(src_tokenizer, 'demo_tokenizers/src_tokenizer.json')\n",
    "save_tokenizer(tgt_tokenizer, 'demo_tokenizers/tgt_tokenizer.json')\n",
    "\n",
    "print(\"모델과 토크나이저가 저장되었습니다!\")\n",
    "print(\"- 모델: demo_checkpoints/demo_model.pth\")\n",
    "print(\"- 소스 토크나이저: demo_tokenizers/src_tokenizer.json\")\n",
    "print(\"- 타겟 토크나이저: demo_tokenizers/tgt_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d929afd",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "이 데모에서는 다음을 수행했습니다:\n",
    "\n",
    "1. **데이터 준비**: 영어-한국어 번역 샘플 데이터 생성\n",
    "2. **토크나이저**: BPE 토크나이저로 텍스트를 토큰화\n",
    "3. **모델 구축**: Transformer 아키텍처 구현 및 분석\n",
    "4. **학습**: 짧은 학습 세션으로 모델 훈련\n",
    "5. **평가**: 간단한 번역 테스트 수행\n",
    "6. **시각화**: 학습 곡선과 어텐션 가중치 시각화\n",
    "\n",
    "### 개선 방향:\n",
    "- 더 큰 데이터셋 사용\n",
    "- 더 긴 학습 시간\n",
    "- 하이퍼파라미터 튜닝\n",
    "- Beam search 디코딩\n",
    "- BLEU 점수 등 정량적 평가 지표 추가\n",
    "\n",
    "전체 학습을 위해서는 `train.py` 스크립트를 실행하세요!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
